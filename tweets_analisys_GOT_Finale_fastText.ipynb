{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tisch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n",
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import csv\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import itertools\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_smileys():\n",
    "    \n",
    "    return {\n",
    "        \":‑)\":\"smiley\",\n",
    "        \":-]\":\"smiley\",\n",
    "        \":-3\":\"smiley\",\n",
    "        \":->\":\"smiley\",\n",
    "        \"8-)\":\"smiley\",\n",
    "        \":-}\":\"smiley\",\n",
    "        \":)\":\"smiley\",\n",
    "        \":]\":\"smiley\",\n",
    "        \":3\":\"smiley\",\n",
    "        \":>\":\"smiley\",\n",
    "        \"8)\":\"smiley\",\n",
    "        \":}\":\"smiley\",\n",
    "        \":o)\":\"smiley\",\n",
    "        \":c)\":\"smiley\",\n",
    "        \":^)\":\"smiley\",\n",
    "        \"=]\":\"smiley\",\n",
    "        \"=)\":\"smiley\",\n",
    "        \":-))\":\"smiley\",\n",
    "        \":‑D\":\"smiley\",\n",
    "        \"8‑D\":\"smiley\",\n",
    "        \"x‑D\":\"smiley\",\n",
    "        \"X‑D\":\"smiley\",\n",
    "        \":D\":\"smiley\",\n",
    "        \"8D\":\"smiley\",\n",
    "        \"xD\":\"smiley\",\n",
    "        \"XD\":\"smiley\",\n",
    "        \":‑(\":\"sad\",\n",
    "        \":‑c\":\"sad\",\n",
    "        \":‑<\":\"sad\",\n",
    "        \":‑[\":\"sad\",\n",
    "        \":(\":\"sad\",\n",
    "        \":c\":\"sad\",\n",
    "        \":<\":\"sad\",\n",
    "        \":[\":\"sad\",\n",
    "        \":-||\":\"sad\",\n",
    "        \">:[\":\"sad\",\n",
    "        \":{\":\"sad\",\n",
    "        \":@\":\"sad\",\n",
    "        \">:(\":\"sad\",\n",
    "        \":'‑(\":\"sad\",\n",
    "        \":'(\":\"sad\",\n",
    "        \":‑P\":\"playful\",\n",
    "        \"X‑P\":\"playful\",\n",
    "        \"x‑p\":\"playful\",\n",
    "        \":‑p\":\"playful\",\n",
    "        \":‑Þ\":\"playful\",\n",
    "        \":‑þ\":\"playful\",\n",
    "        \":‑b\":\"playful\",\n",
    "        \":P\":\"playful\",\n",
    "        \"XP\":\"playful\",\n",
    "        \"xp\":\"playful\",\n",
    "        \":p\":\"playful\",\n",
    "        \":Þ\":\"playful\",\n",
    "        \":þ\":\"playful\",\n",
    "        \":b\":\"playful\",\n",
    "        \"<3\":\"love\"\n",
    "        }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self defined contractions\n",
    "def load_dict_contractions():\n",
    "    \n",
    "    return {\n",
    "        \"ain't\":\"is not\",\n",
    "        \"amn't\":\"am not\",\n",
    "        \"aren't\":\"are not\",\n",
    "        \"can't\":\"cannot\",\n",
    "        \"'cause\":\"because\",\n",
    "        \"couldn't\":\"could not\",\n",
    "        \"couldn't've\":\"could not have\",\n",
    "        \"could've\":\"could have\",\n",
    "        \"daren't\":\"dare not\",\n",
    "        \"daresn't\":\"dare not\",\n",
    "        \"dasn't\":\"dare not\",\n",
    "        \"didn't\":\"did not\",\n",
    "        \"doesn't\":\"does not\",\n",
    "        \"don't\":\"do not\",\n",
    "        \"e'er\":\"ever\",\n",
    "        \"em\":\"them\",\n",
    "        \"everyone's\":\"everyone is\",\n",
    "        \"finna\":\"fixing to\",\n",
    "        \"gimme\":\"give me\",\n",
    "        \"gonna\":\"going to\",\n",
    "        \"gon't\":\"go not\",\n",
    "        \"gotta\":\"got to\",\n",
    "        \"hadn't\":\"had not\",\n",
    "        \"hasn't\":\"has not\",\n",
    "        \"haven't\":\"have not\",\n",
    "        \"he'd\":\"he would\",\n",
    "        \"he'll\":\"he will\",\n",
    "        \"he's\":\"he is\",\n",
    "        \"he've\":\"he have\",\n",
    "        \"how'd\":\"how would\",\n",
    "        \"how'll\":\"how will\",\n",
    "        \"how're\":\"how are\",\n",
    "        \"how's\":\"how is\",\n",
    "        \"I'd\":\"I would\",\n",
    "        \"I'll\":\"I will\",\n",
    "        \"I'm\":\"I am\",\n",
    "        \"I'm'a\":\"I am about to\",\n",
    "        \"I'm'o\":\"I am going to\",\n",
    "        \"isn't\":\"is not\",\n",
    "        \"it'd\":\"it would\",\n",
    "        \"it'll\":\"it will\",\n",
    "        \"it's\":\"it is\",\n",
    "        \"I've\":\"I have\",\n",
    "        \"kinda\":\"kind of\",\n",
    "        \"let's\":\"let us\",\n",
    "        \"mayn't\":\"may not\",\n",
    "        \"may've\":\"may have\",\n",
    "        \"mightn't\":\"might not\",\n",
    "        \"might've\":\"might have\",\n",
    "        \"mustn't\":\"must not\",\n",
    "        \"mustn't've\":\"must not have\",\n",
    "        \"must've\":\"must have\",\n",
    "        \"needn't\":\"need not\",\n",
    "        \"ne'er\":\"never\",\n",
    "        \"o'\":\"of\",\n",
    "        \"o'er\":\"over\",\n",
    "        \"ol'\":\"old\",\n",
    "        \"oughtn't\":\"ought not\",\n",
    "        \"shalln't\":\"shall not\",\n",
    "        \"shan't\":\"shall not\",\n",
    "        \"she'd\":\"she would\",\n",
    "        \"she'll\":\"she will\",\n",
    "        \"she's\":\"she is\",\n",
    "        \"shouldn't\":\"should not\",\n",
    "        \"shouldn't've\":\"should not have\",\n",
    "        \"should've\":\"should have\",\n",
    "        \"somebody's\":\"somebody is\",\n",
    "        \"someone's\":\"someone is\",\n",
    "        \"something's\":\"something is\",\n",
    "        \"that'd\":\"that would\",\n",
    "        \"that'll\":\"that will\",\n",
    "        \"that're\":\"that are\",\n",
    "        \"that's\":\"that is\",\n",
    "        \"there'd\":\"there would\",\n",
    "        \"there'll\":\"there will\",\n",
    "        \"there're\":\"there are\",\n",
    "        \"there's\":\"there is\",\n",
    "        \"these're\":\"these are\",\n",
    "        \"they'd\":\"they would\",\n",
    "        \"they'll\":\"they will\",\n",
    "        \"they're\":\"they are\",\n",
    "        \"they've\":\"they have\",\n",
    "        \"this's\":\"this is\",\n",
    "        \"those're\":\"those are\",\n",
    "        \"'tis\":\"it is\",\n",
    "        \"'twas\":\"it was\",\n",
    "        \"wanna\":\"want to\",\n",
    "        \"wasn't\":\"was not\",\n",
    "        \"we'd\":\"we would\",\n",
    "        \"we'd've\":\"we would have\",\n",
    "        \"we'll\":\"we will\",\n",
    "        \"we're\":\"we are\",\n",
    "        \"weren't\":\"were not\",\n",
    "        \"we've\":\"we have\",\n",
    "        \"what'd\":\"what did\",\n",
    "        \"what'll\":\"what will\",\n",
    "        \"what're\":\"what are\",\n",
    "        \"what's\":\"what is\",\n",
    "        \"what've\":\"what have\",\n",
    "        \"when's\":\"when is\",\n",
    "        \"where'd\":\"where did\",\n",
    "        \"where're\":\"where are\",\n",
    "        \"where's\":\"where is\",\n",
    "        \"where've\":\"where have\",\n",
    "        \"which's\":\"which is\",\n",
    "        \"who'd\":\"who would\",\n",
    "        \"who'd've\":\"who would have\",\n",
    "        \"who'll\":\"who will\",\n",
    "        \"who're\":\"who are\",\n",
    "        \"who's\":\"who is\",\n",
    "        \"who've\":\"who have\",\n",
    "        \"why'd\":\"why did\",\n",
    "        \"why're\":\"why are\",\n",
    "        \"why's\":\"why is\",\n",
    "        \"won't\":\"will not\",\n",
    "        \"wouldn't\":\"would not\",\n",
    "        \"would've\":\"would have\",\n",
    "        \"y'all\":\"you all\",\n",
    "        \"you'd\":\"you would\",\n",
    "        \"you'll\":\"you will\",\n",
    "        \"you're\":\"you are\",\n",
    "        \"you've\":\"you have\",\n",
    "        \"Whatcha\":\"What are you\",\n",
    "        \"luv\":\"love\",\n",
    "        \"sux\":\"sucks\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-20 10:43:00</td>\n",
       "      <td>RT @acursedlove: EVERYBODY LET’S SAY THANK YOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-20 10:38:52</td>\n",
       "      <td>RT @lMMUNlTYIDOL: rip two of the most interest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-20 10:28:58</td>\n",
       "      <td>Throwback to one of the best frames that ever ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-20 10:27:51</td>\n",
       "      <td>Hale and hearty, #KitHarington has reportedly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-20 10:26:08</td>\n",
       "      <td>@dino_melaye Good day twitter sir please help ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                               text\n",
       "0  2019-06-20 10:43:00  RT @acursedlove: EVERYBODY LET’S SAY THANK YOU...\n",
       "1  2019-06-20 10:38:52  RT @lMMUNlTYIDOL: rip two of the most interest...\n",
       "2  2019-06-20 10:28:58  Throwback to one of the best frames that ever ...\n",
       "3  2019-06-20 10:27:51  Hale and hearty, #KitHarington has reportedly ...\n",
       "4  2019-06-20 10:26:08  @dino_melaye Good day twitter sir please help ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.read_csv('GOT_tweets_raw.csv', index_col = 0)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @acursedlove: EVERYBODY LET’S SAY THANK YOU TO THE BEST CAST EVER. \\r\\n\\r\\n#GamefThrones #GameOfThronesFinale \\r\\n#TheFinalEpisode https://t.co/w…',\n",
       " 'RT @lMMUNlTYIDOL: rip two of the most interesting characters game of thrones (and television in general) has ever seen :( cersei and jaime…',\n",
       " 'Throwback to one of the best frames that ever graced TV. #gameofthronesfinale #tvseries #tbt https://t.co/eLPrESZVAJ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = list(twitter_df['text'])\n",
    "tweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @acursedlove: EVERYBODY LET’S SAY THANK YOU TO THE BEST CAST EVER. \\r\\n\\r\\n#GamefThrones #GameOfThronesFinale \\r\\n#TheFinalEpisode https://t.co/w…',\n",
       " 'RT @lMMUNlTYIDOL: rip two of the most interesting characters game of thrones (and television in general) has ever seen :( cersei and jaime…',\n",
       " 'Throwback to one of the best frames that ever graced TV. #gameofthronesfinale #tvseries #tbt https://t.co/eLPrESZVAJ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escaping HTML characters\n",
    "tweets = [BeautifulSoup(elem).get_text() for elem in tweets]\n",
    "tweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @acursedlove: EVERYBODY LET’S SAY THANK YOU TO THE BEST CAST EVER. \\r\\n\\r\\n#GamefThrones #GameOfThronesFinale \\r\\n#TheFinalEpisode https://t.co/w…',\n",
       " 'RT @lMMUNlTYIDOL: rip two of the most interesting characters game of thrones (and television in general) has ever seen :( cersei and jaime…',\n",
       " 'Throwback to one of the best frames that ever graced TV. #gameofthronesfinale #tvseries #tbt https://t.co/eLPrESZVAJ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Special case not handled previously.\n",
    "tweets = [elem.replace('\\x92',\"'\") for elem in tweets]\n",
    "tweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT : EVERYBODY LET’S SAY THANK YOU TO THE BEST CAST EVER. https://t.co/w…',\n",
       " 'RT : rip two of the most interesting characters game of thrones (and television in general) has ever seen :( cersei and jaime…',\n",
       " 'Throwback to one of the best frames that ever graced TV. https://t.co/eLPrESZVAJ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of hastags/account\n",
    "tweets = [' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", elem).split()) for elem in tweets]\n",
    "tweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT : EVERYBODY LET’S SAY THANK YOU TO THE BEST CAST EVER.',\n",
       " 'RT : rip two of the most interesting characters game of thrones (and television in general) has ever seen :( cersei and jaime…',\n",
       " 'Throwback to one of the best frames that ever graced TV.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of address\n",
    "tweets = [' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", elem).split()) for elem in tweets]\n",
    "tweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT EVERYBODY LET’S SAY THANK YOU TO THE BEST CAST EVER',\n",
       " 'RT rip two of the most interesting characters game of thrones (and television in general) has ever seen ( cersei and jaime…',\n",
       " 'Throwback to one of the best frames that ever graced TV']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of Punctuation\n",
    "tweets = [' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", elem).split()) for elem in tweets]\n",
    "tweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt everybody let’s say thank you to the best cast ever',\n",
       " 'rt rip two of the most interesting characters game of thrones (and television in general) has ever seen ( cersei and jaime…',\n",
       " 'throwback to one of the best frames that ever graced tv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lower case\n",
    "tweets = [elem.lower() for elem in tweets]\n",
    "tweets[:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt everybody let us say thank you to the best cast ever',\n",
       " 'rt rip two of the most interesting characters game of thrones (and television in general) has ever seen ( cersei and jaime…',\n",
       " 'throwback to one of the best frames that ever graced tv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
    "CONTRACTIONS = load_dict_contractions()\n",
    "tweets = [elem.replace(\"’\",\"'\") for elem in tweets]\n",
    "words = [elem.split() for elem in tweets]\n",
    "reformed = []\n",
    "for tweet_words in words:\n",
    "    reformed.append([CONTRACTIONS.get(word, word) for word in tweet_words]) # CONTRACTIONS.get(word, word) == CONTRACTIONS[word] if word in CONSTRACTIONS else word\n",
    "tweets = [\" \".join(tweet_words_reformed) for tweet_words_reformed in reformed]\n",
    "tweets[:3]\n",
    "\n",
    "# tweet = tweet.replace(\"’\",\"'\")\n",
    "# words = tweet.split()\n",
    "# reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
    "# tweet = \" \".join(reformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt everybody let us say thank you to the best cast ever',\n",
       " 'rt rip two of the most interesting characters game of thrones (and television in general) has ever seen ( cersei and jaime…',\n",
       " 'throwback to one of the best frames that ever graced tv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing words, misspelled words fix => checking that each character should occur not more than 2 times in every word\n",
    "tweets1 = []\n",
    "for tweet in tweets:\n",
    "    tweets1.append(''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet)))\n",
    "tweets1[:3]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt everybody let us say thank you to the best cast ever',\n",
       " 'rt rip two of the most interesting characters game of thrones (and television in general) has ever seen ( cersei and jaime…',\n",
       " 'throwback to one of the best frames that ever graced tv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deal with emoticons source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
    "SMILEY = load_dict_smileys()  \n",
    "words = [tweet.split() for tweet in tweets1]\n",
    "reformed = []\n",
    "for tweet_words in words:\n",
    "    reformed.append([SMILEY.get(word, word) for word in tweet_words])\n",
    "tweets1 = [\" \".join(tweet_words_reformed) for tweet_words_reformed in reformed]\n",
    "tweets1[:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt everybody let us say thank you to the best cast ever',\n",
       " 'rt rip two of the most interesting characters game of thrones (and television in general) has ever seen ( cersei and jaime…',\n",
       " 'throwback to one of the best frames that ever graced tv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deal with emojis\n",
    "tweets1 = [emoji.demojize(tweet) for tweet in tweets1]\n",
    "tweets1[:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt everybody let us say thank you to the best cast ever',\n",
       " 'rt rip two of the most interesting characters game of thrones (and television in general) has ever seen ( cersei and jaime…',\n",
       " 'throwback to one of the best frames that ever graced tv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets1\n",
    "tweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PROCESSING\n",
    "#\n",
    "#####################################################################################\n",
    "\n",
    "# def transform_instance(row):\n",
    "#     cur_row = []\n",
    "#     #Prefix the index-ed label with __label__\n",
    "#     label = \"__label__\" + row[4]  \n",
    "#     cur_row.append(label)\n",
    "#     cur_row.extend(nltk.word_tokenize(tweet_cleaning_for_sentiment_analysis(row[2].lower())))\n",
    "#     return cur_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(input_file, output_file, keep=1):\n",
    "#     i=0\n",
    "#     with open(output_file, 'w') as csvoutfile:\n",
    "#         csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "#         with open(input_file, 'r', newline='', encoding='latin1') as csvinfile: #,encoding='latin1'\n",
    "#             csv_reader = csv.reader(csvinfile, delimiter=',', quotechar='\"')\n",
    "#             for row in csv_reader:\n",
    "#                 if row[4]!=\"MIXED\" and row[4].upper() in ['POSITIVE','NEGATIVE','NEUTRAL'] and row[2]!='':\n",
    "#                     row_output = transform_instance(row)\n",
    "#                     csv_writer.writerow(row_output )\n",
    "#                     # print(row_output)\n",
    "#                 i=i+1\n",
    "#                 if i%10000 ==0:\n",
    "#                     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from textblob import TextBlob\n",
    "\n",
    "SEED=42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so basically jon snow went through what he had to go through just to get back to what he used to go through loudly_crying_face \n",
      "SENTIMENT: 0.0\n",
      "rt youtuber rewrites got ending and people say that this is how it should have ended\n",
      "SENTIMENT: 0.0\n",
      "kindly help retweet until he sees it coloured ballpen drawing of _dinklage rema messi dybala argentina avengers end game\n",
      "SENTIMENT: 0.09999999999999998\n",
      "sick\n",
      "SENTIMENT: -0.7142857142857143\n",
      "rt say what you will about the the john hughes homage was a bold choice to end on\n",
      "SENTIMENT: 0.3333333333333333\n",
      "mother of dragons shirts glitter or reg tee or tank sizes up to 2x\n",
      "SENTIMENT: 0.0\n",
      "rt drogon destroying the iron throne because new king bran got his own seat …\n",
      "SENTIMENT: 0.1787878787878788\n",
      "rt what a bullshit ending my watch has ended\n",
      "SENTIMENT: 0.0\n",
      "rt say what you will about the the john hughes homage was a bold choice to end on\n",
      "SENTIMENT: 0.3333333333333333\n",
      "rt good fucking riddance these writers should never be allowed to work again\n",
      "SENTIMENT: 0.04999999999999999\n",
      "rt _1da wwttff wass thatt …\n",
      "SENTIMENT: 0.0\n",
      "let us talk about this cute little precious baby  red_heart  red_heart \n",
      "SENTIMENT: 0.2708333333333333\n",
      "how about that i tell ya it sure would be tough to live back then absolutely no ac or electricity wild luckily kong's electric is here to make sure you never have too\n",
      "SENTIMENT: 0.1351010101010101\n",
      "rt it will not end a lot of loose ends they will be back in 5 years just give them a break …\n",
      "SENTIMENT: -0.038461538461538464\n",
      "rt say what you will about the the john hughes homage was a bold choice to end on\n",
      "SENTIMENT: 0.3333333333333333\n",
      "rt killing daenerys is not the end of everything you had a very good opportunity to teach about love to make a world…\n",
      "SENTIMENT: 0.705\n",
      "rt close to a decade of our lives for this\n",
      "SENTIMENT: 0.0\n",
      "rt _kristenleigh “jaime lannister is the nastiest skank bitch i've ever met do not trust him he is a fugly slut ” …\n",
      "SENTIMENT: 0.0\n",
      "rt game of thrones shirt\n",
      "SENTIMENT: -0.4\n",
      "bran the broken  face_with_tears_of_joy \n",
      "SENTIMENT: -0.4\n",
      "lena headey on 'game of thrones' ending 'i wanted a better death' for cersei\n",
      "SENTIMENT: 0.04999999999999999\n",
      "rt _jay_origin ok lemme get this straight jon snow was a targeryen for no reason bran was three eye raven for no reason danny's en…\n",
      "SENTIMENT: 0.35\n",
      "and have a similarity ha ha ha epic failure\n",
      "SENTIMENT: -0.10833333333333335\n",
      "rt do the geneva conventions apply in westeros for the the analysed every violation of internati…\n",
      "SENTIMENT: 0.0\n",
      "this is how should have ended\n",
      "SENTIMENT: 0.0\n",
      "rt special episode on what did you guys what to see\n",
      "SENTIMENT: 0.35714285714285715\n",
      "rt queen in the north lots of symbolism here chose the colors that mostly represent house stark drawing the armor was th…\n",
      "SENTIMENT: 0.15\n",
      "rt 's apology for season 8 is finally out\n",
      "SENTIMENT: 0.0\n",
      "is doin n stuff tone dus a bit ov paintin on th side wassa bit on th side i feel  face_vomiting \n",
      "SENTIMENT: 0.0\n",
      "rt as everyone is been saying arya went west jon went north drogon went east and the series went south …\n",
      "SENTIMENT: 0.0\n"
     ]
    }
   ],
   "source": [
    "sample = random.sample(tweets, 30)\n",
    "for tweet in sample:\n",
    "    tb = TextBlob(tweet)\n",
    "    print(tweet)\n",
    "    print('SENTIMENT: %s' % str(tb.sentiment.polarity)) # \"hello %s\" % (name,) => hello Ela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-20 10:43:00</td>\n",
       "      <td>RT @acursedlove: EVERYBODY LET’S SAY THANK YOU...</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-20 10:38:52</td>\n",
       "      <td>RT @lMMUNlTYIDOL: rip two of the most interest...</td>\n",
       "      <td>0.1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-20 10:28:58</td>\n",
       "      <td>Throwback to one of the best frames that ever ...</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-20 10:27:51</td>\n",
       "      <td>Hale and hearty, #KitHarington has reportedly ...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-20 10:26:08</td>\n",
       "      <td>@dino_melaye Good day twitter sir please help ...</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                               text  \\\n",
       "0  2019-06-20 10:43:00  RT @acursedlove: EVERYBODY LET’S SAY THANK YOU...   \n",
       "1  2019-06-20 10:38:52  RT @lMMUNlTYIDOL: rip two of the most interest...   \n",
       "2  2019-06-20 10:28:58  Throwback to one of the best frames that ever ...   \n",
       "3  2019-06-20 10:27:51  Hale and hearty, #KitHarington has reportedly ...   \n",
       "4  2019-06-20 10:26:08  @dino_melaye Good day twitter sir please help ...   \n",
       "\n",
       "   sentiment  \n",
       "0     1.0000  \n",
       "1     0.1625  \n",
       "2     1.0000  \n",
       "3     0.0000  \n",
       "4     0.7000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    tb = TextBlob(tweet)\n",
    "    scores.append(tb.sentiment.polarity)\n",
    "    \n",
    "twitter_df['sentiment'] = pd.Series(scores)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows containing sentyment == 0.0. Remove duplicates and rows with NaN.\n",
    "twitter_df.shape\n",
    "twitter_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(519, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = twitter_df[twitter_df['sentiment']!=0.0]\n",
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of rows with positive and negative sentiment, calculate the percentage\n",
    "\n",
    "twitter_df[twitter_df['sentiment'] > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df[twitter_df['sentiment'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive sentiment = \n",
      "60.22\n",
      "positive sentiment = \n",
      "39.78\n"
     ]
    }
   ],
   "source": [
    "positive_sent = 224/372*100\n",
    "negative_sent = 148/372*100\n",
    "print('positive sentiment = ') \n",
    "print(round(positive_sent,2))\n",
    "print('positive sentiment = ')\n",
    "print(round(negative_sent,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-1.0, -0.8]</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.8, -0.6]</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.6, -0.4]</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.4, -0.2]</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.2, -2.22e-16]</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-2.22e-16, 0.2]</th>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.2, 0.4]</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.4, 0.6]</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.6, 0.8]</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.8, 1.0]</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  text  sentiment\n",
       "sentiment                               \n",
       "(-1.0, -0.8]          0     0          0\n",
       "(-0.8, -0.6]          4     4          4\n",
       "(-0.6, -0.4]         16    16         16\n",
       "(-0.4, -0.2]        116   116        116\n",
       "(-0.2, -2.22e-16]    68    68         68\n",
       "(-2.22e-16, 0.2]    118   118        118\n",
       "(0.2, 0.4]          124   124        124\n",
       "(0.4, 0.6]           52    52         52\n",
       "(0.6, 0.8]           16    16         16\n",
       "(0.8, 1.0]           10    10         10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate N of rows with sentyment in estimated borders. \n",
    "# Use groupby qnd cut functions: https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.cut.html\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "twitter_df.groupby(pd.cut(twitter_df['sentiment'], np.arange(-1, 1+0.2, 0.2))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/20/2019 10:43</td>\n",
       "      <td>RT @acursedlove: EVERYBODY LET’S SAY THANK YOU...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/20/2019 10:38</td>\n",
       "      <td>RT @lMMUNlTYIDOL: rip two of the most interest...</td>\n",
       "      <td>0.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/20/2019 10:26</td>\n",
       "      <td>RT @lady_ifrit: 🎉🎉🎉🎉The weapon of Arya Stark i...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6/20/2019 9:28</td>\n",
       "      <td>RT @jgamir: Game of Thrones #GameOfThronesFina...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6/20/2019 9:11</td>\n",
       "      <td>#ThursdayThoughts #GameOfThronesFinale \\r\\nIt'...</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6/20/2019 6:49</td>\n",
       "      <td>Bereket is coming..\\r\\n#GameOfThronesFinale</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6/20/2019 6:16</td>\n",
       "      <td>Wait, What? #GOT Makers Deleted #CerseiLannist...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6/20/2019 6:03</td>\n",
       "      <td>People Had Incredibly Divided Reactions To The...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6/20/2019 5:50</td>\n",
       "      <td>All of them died for nothing.\\r\\n#GameOfThrone...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6/20/2019 5:28</td>\n",
       "      <td>RT @laurenceraqq: Power of stories | Tyrion La...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6/20/2019 5:25</td>\n",
       "      <td>RT @YinYoungs: Killing Daenerys is not the end...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6/20/2019 4:51</td>\n",
       "      <td>RT @call_me_elliee: Turns out, Jon Snow really...</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6/20/2019 4:11</td>\n",
       "      <td>RT @FoldableHuman: Say what you will about the...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6/20/2019 4:05</td>\n",
       "      <td>Dissapointing pero award winning pa rin naman!...</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6/20/2019 3:04</td>\n",
       "      <td>RT @TeranceTshuma: Close to a decade of our li...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6/20/2019 2:33</td>\n",
       "      <td>RT @iAmpravinsuthar: Say what you will about t...</td>\n",
       "      <td>-0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6/20/2019 0:00</td>\n",
       "      <td>🎉🎉🎉🎉The weapon of Arya Stark is raffled,🎀🎀 to ...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6/19/2019 22:32</td>\n",
       "      <td>Also, I don’t understand the hate on the #Game...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6/19/2019 21:46</td>\n",
       "      <td>RT @piersmorgan: BREAKING: I don't care what h...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6/19/2019 21:43</td>\n",
       "      <td>RT @acursedlove: EVERYBODY LET’S SAY THANK YOU...</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6/19/2019 21:33</td>\n",
       "      <td>RT @udotai_j: Jamie Lannister's kingslayer lev...</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6/19/2019 21:12</td>\n",
       "      <td>Long may she reign #queencersei #cersei #Cerse...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6/19/2019 21:10</td>\n",
       "      <td>“played game of thrones, won, but died” #Daene...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6/19/2019 20:55</td>\n",
       "      <td>RT @jessicalmorgans: My take on the 30 Day Gam...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6/19/2019 20:54</td>\n",
       "      <td>My take on the 30 Day Game of Thrones Challeng...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6/19/2019 19:19</td>\n",
       "      <td>That iconic shot of Daenerys in the last episo...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6/19/2019 19:11</td>\n",
       "      <td>RT @CBR: Game of Thrones Prequel Series Begins...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6/19/2019 18:09</td>\n",
       "      <td>RT @CBR: Game of Thrones Prequel Series Begins...</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6/19/2019 17:02</td>\n",
       "      <td>RT @fentybeauty: When he says you look beautif...</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6/19/2019 16:15</td>\n",
       "      <td>RT @CBR: Game of Thrones Prequel Series Begins...</td>\n",
       "      <td>-0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>6/16/2019 3:00</td>\n",
       "      <td>RT @Brancosalesasso: Fist bump 🤜🤛 would never ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>6/16/2019 1:57</td>\n",
       "      <td>RT @faveslooks: Queen in the North.\\r\\n#Gameof...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>6/16/2019 1:57</td>\n",
       "      <td>RT @robert_sith305: Game of thrones night king...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>6/16/2019 1:37</td>\n",
       "      <td>RT @ThatAnjaliGupta: When Tyrion named BRAN th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>6/16/2019 1:27</td>\n",
       "      <td>Have APPLE PAY CASH SET UP ❓ Flip $30 for $150...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>6/16/2019 1:24</td>\n",
       "      <td>RT @JoyScott13: Don’t mind me, I’m just crying...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>6/16/2019 0:56</td>\n",
       "      <td>RT @1LifeOfDeen: Samwell Tarly: Democracy \\r\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>6/16/2019 0:45</td>\n",
       "      <td>RT @robert_sith305: Game of thrones night king...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>6/16/2019 0:08</td>\n",
       "      <td>RT @robert_sith305: Game of thrones night king...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>6/15/2019 23:41</td>\n",
       "      <td>Endgame? Really? I Don't think so #GameOfThron...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>6/15/2019 23:34</td>\n",
       "      <td>RT @P1Eddie: #GameOfThrones #GameOfThronesFina...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>6/15/2019 23:34</td>\n",
       "      <td>RT @Queenziah: #Thefinaleepisode :\\r\\nDaenerys...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>6/15/2019 23:30</td>\n",
       "      <td>RT @WafflesCat: DIREWOLF bread 😂😂@RosannaPansi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>6/15/2019 23:28</td>\n",
       "      <td>RT @robert_sith305: Game of thrones night king...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>6/15/2019 23:19</td>\n",
       "      <td>RT @robert_sith305: Game of thrones night king...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>6/15/2019 23:16</td>\n",
       "      <td>RT @renegadecut: The #GameofThronesFinale and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>6/15/2019 23:09</td>\n",
       "      <td>Game of thrones night king and Theon recreatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>6/15/2019 22:59</td>\n",
       "      <td>RT @HausofMiren: #gameofthronesfinale - this i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>6/15/2019 22:42</td>\n",
       "      <td>RT @cutewalter_: #GameOfThronesFinale \\r\\n\\r\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>6/15/2019 22:17</td>\n",
       "      <td>RT @realFFK: \"Bend the knee\"-Daenarys Targaray...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>6/15/2019 22:16</td>\n",
       "      <td>RT @renegadecut: The #GameofThronesFinale and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>6/15/2019 22:05</td>\n",
       "      <td>RT @realFFK: \"Bend the knee\"-Daenarys Targaray...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>6/15/2019 21:53</td>\n",
       "      <td>RT @renegadecut: The #GameofThronesFinale and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>6/15/2019 21:53</td>\n",
       "      <td>RT @sritawinterfell: THE MOTHER OF DRAGONS\\r\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>6/15/2019 21:52</td>\n",
       "      <td>RT @udotai_j: Jamie Lannister's kingslayer lev...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>6/15/2019 21:45</td>\n",
       "      <td>RT @realFFK: \"Bend the knee\"-Daenarys Targaray...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>6/15/2019 21:42</td>\n",
       "      <td>RT @cutewalter_: #GameOfThronesFinale \\r\\n\\r\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>6/15/2019 21:25</td>\n",
       "      <td>Meet my Cat Venom, sitting there like he doesn...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>6/15/2019 20:55</td>\n",
       "      <td>RT @TargaryenHaught: D&amp;amp;D are just 2 talent...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>6/15/2019 20:51</td>\n",
       "      <td>RT @TargaryenHaught: D&amp;amp;D are just 2 talent...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date                                               text  \\\n",
       "0    6/20/2019 10:43  RT @acursedlove: EVERYBODY LET’S SAY THANK YOU...   \n",
       "1    6/20/2019 10:38  RT @lMMUNlTYIDOL: rip two of the most interest...   \n",
       "5    6/20/2019 10:26  RT @lady_ifrit: 🎉🎉🎉🎉The weapon of Arya Stark i...   \n",
       "7     6/20/2019 9:28  RT @jgamir: Game of Thrones #GameOfThronesFina...   \n",
       "8     6/20/2019 9:11  #ThursdayThoughts #GameOfThronesFinale \\r\\nIt'...   \n",
       "14    6/20/2019 6:49        Bereket is coming..\\r\\n#GameOfThronesFinale   \n",
       "15    6/20/2019 6:16  Wait, What? #GOT Makers Deleted #CerseiLannist...   \n",
       "17    6/20/2019 6:03  People Had Incredibly Divided Reactions To The...   \n",
       "18    6/20/2019 5:50  All of them died for nothing.\\r\\n#GameOfThrone...   \n",
       "21    6/20/2019 5:28  RT @laurenceraqq: Power of stories | Tyrion La...   \n",
       "22    6/20/2019 5:25  RT @YinYoungs: Killing Daenerys is not the end...   \n",
       "26    6/20/2019 4:51  RT @call_me_elliee: Turns out, Jon Snow really...   \n",
       "28    6/20/2019 4:11  RT @FoldableHuman: Say what you will about the...   \n",
       "29    6/20/2019 4:05  Dissapointing pero award winning pa rin naman!...   \n",
       "32    6/20/2019 3:04  RT @TeranceTshuma: Close to a decade of our li...   \n",
       "34    6/20/2019 2:33  RT @iAmpravinsuthar: Say what you will about t...   \n",
       "38    6/20/2019 0:00  🎉🎉🎉🎉The weapon of Arya Stark is raffled,🎀🎀 to ...   \n",
       "41   6/19/2019 22:32  Also, I don’t understand the hate on the #Game...   \n",
       "42   6/19/2019 21:46  RT @piersmorgan: BREAKING: I don't care what h...   \n",
       "43   6/19/2019 21:43  RT @acursedlove: EVERYBODY LET’S SAY THANK YOU...   \n",
       "44   6/19/2019 21:33  RT @udotai_j: Jamie Lannister's kingslayer lev...   \n",
       "45   6/19/2019 21:12  Long may she reign #queencersei #cersei #Cerse...   \n",
       "46   6/19/2019 21:10  “played game of thrones, won, but died” #Daene...   \n",
       "47   6/19/2019 20:55  RT @jessicalmorgans: My take on the 30 Day Gam...   \n",
       "48   6/19/2019 20:54  My take on the 30 Day Game of Thrones Challeng...   \n",
       "55   6/19/2019 19:19  That iconic shot of Daenerys in the last episo...   \n",
       "57   6/19/2019 19:11  RT @CBR: Game of Thrones Prequel Series Begins...   \n",
       "58   6/19/2019 18:09  RT @CBR: Game of Thrones Prequel Series Begins...   \n",
       "60   6/19/2019 17:02  RT @fentybeauty: When he says you look beautif...   \n",
       "61   6/19/2019 16:15  RT @CBR: Game of Thrones Prequel Series Begins...   \n",
       "..               ...                                                ...   \n",
       "789   6/16/2019 3:00  RT @Brancosalesasso: Fist bump 🤜🤛 would never ...   \n",
       "790   6/16/2019 1:57  RT @faveslooks: Queen in the North.\\r\\n#Gameof...   \n",
       "791   6/16/2019 1:57  RT @robert_sith305: Game of thrones night king...   \n",
       "792   6/16/2019 1:37  RT @ThatAnjaliGupta: When Tyrion named BRAN th...   \n",
       "793   6/16/2019 1:27  Have APPLE PAY CASH SET UP ❓ Flip $30 for $150...   \n",
       "794   6/16/2019 1:24  RT @JoyScott13: Don’t mind me, I’m just crying...   \n",
       "795   6/16/2019 0:56  RT @1LifeOfDeen: Samwell Tarly: Democracy \\r\\n...   \n",
       "796   6/16/2019 0:45  RT @robert_sith305: Game of thrones night king...   \n",
       "797   6/16/2019 0:08  RT @robert_sith305: Game of thrones night king...   \n",
       "798  6/15/2019 23:41  Endgame? Really? I Don't think so #GameOfThron...   \n",
       "799  6/15/2019 23:34  RT @P1Eddie: #GameOfThrones #GameOfThronesFina...   \n",
       "800  6/15/2019 23:34  RT @Queenziah: #Thefinaleepisode :\\r\\nDaenerys...   \n",
       "801  6/15/2019 23:30  RT @WafflesCat: DIREWOLF bread 😂😂@RosannaPansi...   \n",
       "802  6/15/2019 23:28  RT @robert_sith305: Game of thrones night king...   \n",
       "803  6/15/2019 23:19  RT @robert_sith305: Game of thrones night king...   \n",
       "804  6/15/2019 23:16  RT @renegadecut: The #GameofThronesFinale and ...   \n",
       "805  6/15/2019 23:09  Game of thrones night king and Theon recreatio...   \n",
       "806  6/15/2019 22:59  RT @HausofMiren: #gameofthronesfinale - this i...   \n",
       "807  6/15/2019 22:42  RT @cutewalter_: #GameOfThronesFinale \\r\\n\\r\\n...   \n",
       "808  6/15/2019 22:17  RT @realFFK: \"Bend the knee\"-Daenarys Targaray...   \n",
       "809  6/15/2019 22:16  RT @renegadecut: The #GameofThronesFinale and ...   \n",
       "810  6/15/2019 22:05  RT @realFFK: \"Bend the knee\"-Daenarys Targaray...   \n",
       "811  6/15/2019 21:53  RT @renegadecut: The #GameofThronesFinale and ...   \n",
       "812  6/15/2019 21:53  RT @sritawinterfell: THE MOTHER OF DRAGONS\\r\\n...   \n",
       "813  6/15/2019 21:52  RT @udotai_j: Jamie Lannister's kingslayer lev...   \n",
       "814  6/15/2019 21:45  RT @realFFK: \"Bend the knee\"-Daenarys Targaray...   \n",
       "815  6/15/2019 21:42  RT @cutewalter_: #GameOfThronesFinale \\r\\n\\r\\n...   \n",
       "816  6/15/2019 21:25  Meet my Cat Venom, sitting there like he doesn...   \n",
       "817  6/15/2019 20:55  RT @TargaryenHaught: D&amp;D are just 2 talent...   \n",
       "818  6/15/2019 20:51  RT @TargaryenHaught: D&amp;D are just 2 talent...   \n",
       "\n",
       "     sentiment  \n",
       "0     1.000000  \n",
       "1     0.162500  \n",
       "5     0.250000  \n",
       "7    -0.400000  \n",
       "8     0.437500  \n",
       "14    0.705000  \n",
       "15    1.000000  \n",
       "17    0.200000  \n",
       "18    0.333333  \n",
       "21    1.000000  \n",
       "22    0.333333  \n",
       "26   -0.050000  \n",
       "28    1.000000  \n",
       "29    0.160000  \n",
       "32   -0.400000  \n",
       "34   -0.033333  \n",
       "38    0.250000  \n",
       "41   -0.400000  \n",
       "42   -0.400000  \n",
       "43   -0.333333  \n",
       "44    0.850000  \n",
       "45   -0.400000  \n",
       "46   -0.400000  \n",
       "47   -0.400000  \n",
       "48   -0.400000  \n",
       "55    0.200000  \n",
       "57   -0.400000  \n",
       "58    0.300000  \n",
       "60    0.160000  \n",
       "61   -0.300000  \n",
       "..         ...  \n",
       "789        NaN  \n",
       "790        NaN  \n",
       "791        NaN  \n",
       "792        NaN  \n",
       "793        NaN  \n",
       "794        NaN  \n",
       "795        NaN  \n",
       "796        NaN  \n",
       "797        NaN  \n",
       "798        NaN  \n",
       "799        NaN  \n",
       "800        NaN  \n",
       "801        NaN  \n",
       "802        NaN  \n",
       "803        NaN  \n",
       "804        NaN  \n",
       "805        NaN  \n",
       "806        NaN  \n",
       "807        NaN  \n",
       "808        NaN  \n",
       "809        NaN  \n",
       "810        NaN  \n",
       "811        NaN  \n",
       "812        NaN  \n",
       "813        NaN  \n",
       "814        NaN  \n",
       "815        NaN  \n",
       "816        NaN  \n",
       "817        NaN  \n",
       "818        NaN  \n",
       "\n",
       "[451 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
